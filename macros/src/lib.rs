// TODO clean up â€“ was generated by o-1 https://chatgpt.com/c/67dad45d-8e28-8000-82dd-21dc9e9a4cf3

use proc_macro::TokenStream;
use quote::quote;
use syn::{
    parse::{Parse, ParseStream, Parser},
    punctuated::Punctuated,
    token, Error as SynError, Ident, LitBool, LitFloat, LitInt, LitStr, Token,
};
/// The user-facing macro. We'll detect if the input is `include!(...)` or `include!(concat!(...))`,
/// read the file ourselves, parse it, otherwise fallback to normal DSL parse.
#[proc_macro]
pub fn sdql_static(input: TokenStream) -> TokenStream {
    let ts = proc_macro2::TokenStream::from(input);

    // Try to see if we have top-level `include!(...)` usage
    if let Some(file_tokens) = try_expand_include_manually(&ts) {
        // If we successfully read the file, parse it as DSL
        match syn::parse2::<SdqlValue>(file_tokens) {
            Ok(ast) => {
                let gen = ast.into_token_stream();
                return gen.into();
            }
            Err(e) => return e.to_compile_error().into(),
        }
    }

    // If that didn't work or wasn't recognized, parse the usual DSL from the original tokens
    match syn::parse2::<SdqlValue>(ts) {
        Ok(ast) => {
            let gen = ast.into_token_stream();
            gen.into()
        }
        Err(e) => e.to_compile_error().into(),
    }
}

/// Detect if the input is exactly `include!(...)` or `include!(concat!(...))`,
/// read the file, and return a TokenStream of the file's contents if possible.
fn try_expand_include_manually(
    input: &proc_macro2::TokenStream,
) -> Option<proc_macro2::TokenStream> {
    // We'll parse the token stream with a small ad-hoc parser to detect:
    //   IDENT "include"   Punct !   Group(Paren(...))
    // Then inside that group, either a LitStr or a call to "concat!(...)" of multiple LitStr.

    let mut tokens = input.clone().into_iter().peekable();

    // 1) We expect an ident "include"
    let ident = match tokens.next()? {
        proc_macro2::TokenTree::Ident(id) => id,
        _ => return None,
    };
    if ident.to_string() != "include" {
        return None;
    }

    // 2) We expect a punct: `!`
    let _bang = match tokens.next()? {
        proc_macro2::TokenTree::Punct(p) if p.as_char() == '!' => p,
        _ => return None,
    };

    // 3) We expect a group: `( ... )`
    let group = match tokens.next()? {
        proc_macro2::TokenTree::Group(g)
            if g.delimiter() == proc_macro2::Delimiter::Parenthesis =>
        {
            g
        }
        _ => return None,
    };

    // 4) We should have no more tokens after that
    if tokens.peek().is_some() {
        // There's something else => not recognized
        return None;
    }

    // Now parse the inside of the parentheses to see if it's a string literal or concat!(...)
    let inside_ts = group.stream();
    let mut inside_iter = inside_ts.clone().into_iter().peekable();

    if let Some(tt) = inside_iter.peek() {
        // If it's an Ident "concat", parse that specifically
        if let proc_macro2::TokenTree::Ident(id) = tt {
            if id == "concat" {
                // parse `concat!( "part1", "part2", ... )`
                inside_iter.next(); // consume "concat"
                                    // expect `!`
                match inside_iter.next() {
                    Some(proc_macro2::TokenTree::Punct(p)) if p.as_char() == '!' => {}
                    _ => return None,
                }
                // expect `( ... )`
                let group_concat = match inside_iter.next() {
                    Some(proc_macro2::TokenTree::Group(g))
                        if g.delimiter() == proc_macro2::Delimiter::Parenthesis =>
                    {
                        g
                    }
                    _ => return None,
                };
                // parse a comma-separated list of string literals
                let concat_parts = parse_concat_args(group_concat.stream())?;
                let path = concat_parts.join("");
                // read the file
                return read_file_as_tokenstream(&path).ok();
            }
        }
    }

    // Otherwise, see if the entire thing is just a single string literal
    let lit_path = parse_single_str_literal(inside_ts)?;
    return read_file_as_tokenstream(&lit_path).ok();
}

/// Helper: parse a single string literal out of the tokens
fn parse_single_str_literal(ts: proc_macro2::TokenStream) -> Option<String> {
    let mut iter = ts.into_iter().peekable();
    let first = iter.next()?;
    // it must be a string literal
    match first {
        proc_macro2::TokenTree::Literal(l) => {
            // convert to Lit (syn can parse it)
            let lit_str: LitStr = syn::parse_str(&l.to_string()).ok()?;
            // ensure no trailing tokens
            if iter.peek().is_some() {
                return None;
            }
            return Some(lit_str.value());
        }
        _ => None,
    }
}

/// Helper: parse something like `"foo", "bar", "baz"` inside `concat!(...)`.
fn parse_concat_args(ts: proc_macro2::TokenStream) -> Option<Vec<String>> {
    // We'll parse it with syn's Punctuated: multiple lit-str separated by commas
    let parser = Punctuated::<LitStr, Token![,]>::parse_terminated;
    let inside = match parser.parse2(ts) {
        Ok(punct) => punct,
        Err(_) => return None,
    };
    let vals: Vec<String> = inside.into_iter().map(|s| s.value()).collect();
    Some(vals)
}

/// Actually read the file from disk at compile time, parse it as tokens
fn read_file_as_tokenstream(path: &str) -> Result<proc_macro2::TokenStream, SynError> {
    use std::fs;
    let content = fs::read_to_string(path).map_err(|e| {
        SynError::new(
            proc_macro2::Span::call_site(),
            format!("Failed reading file {path:?}: {e}"),
        )
    })?;

    // Now parse that content as a token stream.
    content.parse::<proc_macro2::TokenStream>().map_err(|e| {
        SynError::new(
            proc_macro2::Span::call_site(),
            format!("Token parse error: {e}"),
        )
    })
}

/// Internal AST for our DSL. (No derive to avoid issues with Lit*.)
enum SdqlValue {
    /// e.g. `{ key -> value, key2 -> value2, ... }`
    Map(Vec<(SdqlValue, SdqlValue)>),

    /// e.g. `<val1, val2, ...>` => `Record::new((val1, val2, ...))`
    Record(Vec<SdqlValue>),

    /// e.g. `date(12345)` => `date!(12345)`
    Date(LitInt),

    /// booleans => `TRUE` / `FALSE`
    Bool(bool),

    /// integer literal => e.g. `10691`
    Int(LitInt),

    /// float literal => e.g. `3.14` => `OrderedFloat(3.14)`
    Float(LitFloat),

    /// negative integer => e.g. `-123`
    NegativeInt(LitInt),

    /// negative float => e.g. `-3.14`
    NegativeFloat(LitFloat),

    /// string literal => `"CHINA"` => `VarChar::from("CHINA").unwrap()`
    StringLit(LitStr),
}

impl Parse for SdqlValue {
    fn parse(input: ParseStream) -> syn::Result<Self> {
        // 1) If braces => parse a map: { k -> v, ... }
        if input.peek(token::Brace) {
            return parse_map(input);
        }

        // 2) If `<` => parse a record
        if input.peek(Token![<]) {
            return parse_record(input);
        }

        // 3) If a leading minus => parse negative number
        if input.peek(Token![-]) {
            let _minus: Token![-] = input.parse()?;
            if input.peek(LitFloat) {
                let lf: LitFloat = input.parse()?;
                return Ok(SdqlValue::NegativeFloat(lf));
            } else if input.peek(LitInt) {
                let li: LitInt = input.parse()?;
                return Ok(SdqlValue::NegativeInt(li));
            } else {
                return Err(syn::Error::new(
                    input.span(),
                    "expected numeric literal after '-'",
                ));
            }
        }

        // 4) If it's a boolean literal `true` / `false`
        if input.peek(LitBool) {
            let lb: LitBool = input.parse()?;
            return Ok(SdqlValue::Bool(lb.value()));
        }

        // 5) If it's an Ident => possibly `date(...)`
        if input.peek(Ident) {
            let ident: Ident = input.parse()?;
            match ident.to_string().as_str() {
                "date" => {
                    // parse date(...) => date!(...)
                    let content;
                    syn::parenthesized!(content in input);
                    let inner: LitInt = content.parse()?;
                    // IMPORTANT: return after constructing the SdqlValue!
                    return Ok(SdqlValue::Date(inner));
                }
                _ => {
                    return Err(syn::Error::new_spanned(
                        ident,
                        "expected `date(...)` or recognized keyword",
                    ));
                }
            }
        }

        // 6) If it's a numeric literal => parse int or float
        if input.peek(LitFloat) {
            let lf: LitFloat = input.parse()?;
            return Ok(SdqlValue::Float(lf));
        }
        if input.peek(LitInt) {
            let li: LitInt = input.parse()?;
            return Ok(SdqlValue::Int(li));
        }

        // 6) string literal => `"CHINA"` => StringLit("CHINA")
        if input.peek(LitStr) {
            let ls: LitStr = input.parse()?;
            return Ok(SdqlValue::StringLit(ls));
        }

        // Otherwise, no match
        Err(syn::Error::new(
            input.span(),
            "unrecognized token in sdql_static!()",
        ))
    }
}

/// Parse a map of the form `{ k -> v, k2 -> v2, ... }`.
fn parse_map(input: ParseStream) -> syn::Result<SdqlValue> {
    let content;
    let _brace = syn::braced!(content in input);

    let mut pairs = Vec::new();
    while !content.is_empty() {
        // parse "key"
        let key = SdqlValue::parse(&content)?;
        // parse "->"
        let _arrow: Token![->] = content.parse()?;
        // parse "value"
        let val = SdqlValue::parse(&content)?;

        pairs.push((key, val));

        // optional comma
        if content.peek(Token![,]) {
            content.parse::<Token![,]>()?;
        } else {
            break;
        }
    }

    Ok(SdqlValue::Map(pairs))
}

/// Parse a record of the form `< val1, val2, ... >`.
fn parse_record(input: ParseStream) -> syn::Result<SdqlValue> {
    let _lt: Token![<] = input.parse()?;
    let mut values = Vec::new();

    while !input.peek(Token![>]) {
        let val = SdqlValue::parse(input)?;
        values.push(val);

        if input.peek(Token![,]) {
            input.parse::<Token![,]>()?;
        } else {
            break;
        }
    }

    let _gt: Token![>] = input.parse()?;
    Ok(SdqlValue::Record(values))
}

// Convert the SdqlValue AST into Rust code via quote!
impl SdqlValue {
    fn into_token_stream(self) -> proc_macro2::TokenStream {
        match self {
            SdqlValue::Map(pairs) => {
                // => HashMap::from([ (k, v), ... ])
                let pairs_ts = pairs.into_iter().map(|(k, v)| {
                    let k_ts = k.into_token_stream();
                    let v_ts = v.into_token_stream();
                    quote! { (#k_ts, #v_ts) }
                });
                quote! {
                    ::sdql_runtime::HashMap::from([ #( #pairs_ts ),* ])
                }
            }
            SdqlValue::Record(vals) => {
                // => Record::new((val1, val2, ...))
                let elems = vals.into_iter().map(|v| v.into_token_stream());
                quote! {
                    ::sdql_runtime::Record::new(( #( #elems ),* ))
                }
            }
            SdqlValue::Date(li) => {
                // => date!(nnnn)
                quote! { ::sdql_runtime::date!(#li) }
            }
            SdqlValue::Bool(true) => quote! { ::sdql_runtime::TRUE },
            SdqlValue::Bool(false) => quote! { ::sdql_runtime::FALSE },
            SdqlValue::Int(li) => quote! { #li },
            SdqlValue::Float(lf) => quote! { ::sdql_runtime::OrderedFloat(#lf) },
            SdqlValue::NegativeInt(li) => quote! { -(#li) },
            SdqlValue::NegativeFloat(lf) => quote! { ::sdql_runtime::OrderedFloat(-#lf) },
            SdqlValue::StringLit(ls) => quote! { VarChar::from(#ls).unwrap() },
        }
    }
}
